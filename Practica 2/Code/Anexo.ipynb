{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias para manejar los motores y cámara del robot así como otras que nos ayudarán a trabajar con las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO          \n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from queue import Queue \n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos unas funciones que nos serán útiles para mover el robot y obtener imágenes de la cámara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de pines que usaremos para controlar los motores\n",
    "hMotorPins = [21, 20, 16, 12]\n",
    "vMotorPins = [26, 19, 13, 6]\n",
    "\n",
    "# Secuencia que habrá que enviar para efectuar un ciclo de medios pasos en los motores\n",
    "motorSequence = [\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 0, 0, 0],\n",
    "    [1, 1, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 0, 1, 1],\n",
    "    [0, 0, 0, 1]]\n",
    "\n",
    "\n",
    "def start():\n",
    "    GPIO.setwarnings(False)\n",
    "    GPIO.setmode(GPIO.BCM) # Definimos la forma en que vamos a referenciar los pines\n",
    "    time.sleep(0.1)\n",
    "    # Ponemos todos los pines como out y low\n",
    "    for pin in hMotorPins + vMotorPins:\n",
    "        GPIO.setup(pin, GPIO.OUT)\n",
    "        GPIO.output(pin, 0)\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "def stop():\n",
    "    GPIO.cleanup()\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "### Definimos los distintos movimientos de los motores ###\n",
    "\n",
    "# 512 ciclos harían una revolución completa de motor => 512 / 360 * ángulo = 64 / 45 * ángulo) ciclos nos darán el ángulo que buscamos.\n",
    "# 1 ciclo = 8 medios pasos\n",
    "# En cada medio paso debemos dar valores a 4 pines\n",
    "# Después de dar esos valores, debemos esperar un tiempo mínimo antes del siguiente medio paso\n",
    "\n",
    "def moveRight(cycles):\n",
    "    global curPos\n",
    "    start()\n",
    "    for i in range(cycles):\n",
    "        for halfstep in range(8): \n",
    "            for pin in range(4):  \n",
    "                GPIO.output(hMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.001)\n",
    "        curPos += 1\n",
    "    stop()\n",
    "                        \n",
    "def moveLeft(cycles):\n",
    "    global curPos\n",
    "    start()\n",
    "    for i in range(cycles):\n",
    "        for halfstep in reversed(range(8)):\n",
    "            for pin in reversed(range(4)):\n",
    "                GPIO.output(hMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.001)\n",
    "        curPos -= 1\n",
    "    stop()\n",
    "                \n",
    "\n",
    "def moveUp(cycles):\n",
    "    start()\n",
    "    for i in range(cycles):\n",
    "        for halfstep in reversed(range(8)):\n",
    "            for pin in reversed(range(4)):\n",
    "                GPIO.output(vMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.001)\n",
    "    stop()\n",
    "                \n",
    "\n",
    "def moveDown(cycles):\n",
    "    start()\n",
    "    for i in range(cycles):\n",
    "        for halfstep in range(8):\n",
    "            for pin in range(4):\n",
    "                GPIO.output(vMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.001)\n",
    "    stop()\n",
    "\n",
    "    \n",
    "# Tomaremos 60 fotos dentro de los rangos definidos para cada nodo\n",
    "def get60Images(nodePos, path):\n",
    "    global curPos, frame, takingPhotos\n",
    "    takingPhotos = True\n",
    "    moveLeft(curPos)\n",
    "    for np in range(len(nodePos)):\n",
    "        imNo = 0\n",
    "        pos = nodePos[np]\n",
    "        moveRight(pos[0] - curPos)\n",
    "        time.sleep(0.2)\n",
    "        start()\n",
    "        photoAt = (8 * (pos[1] - pos[0])) / 60 \n",
    "        for i in range(pos[1] - pos[0]):\n",
    "            for halfstep in range(8):\n",
    "                for pin in range(4):\n",
    "                    GPIO.output(hMotorPins[pin], motorSequence[halfstep][pin])\n",
    "                if int((i * 8 + halfstep) % photoAt) == 0:\n",
    "                    time.sleep(0.4)\n",
    "                    cv2.imwrite(path + 'nodo_' + str(np + 1) + '_img_' + str(int(imNo)) + '.jpg', frame) # Guardamos la imagen\n",
    "                    imNo += 1\n",
    "                else:\n",
    "                    time.sleep(0.001)\n",
    "            curPos += 1 \n",
    "        stop()\n",
    "    takingPhotos = False\n",
    "    moveLeft(curPos)\n",
    "\n",
    "    \n",
    "# Esta función nos muestra, con algunas anotaciones (Nodo y posiciones que estamos registrando\n",
    "# y ciclos que giraremos) lo que se está viendo a través de la cámara\n",
    "def showImage(cycles, left, frame, node, nodePos, vl):\n",
    "    global takingPhotos\n",
    "    \n",
    "    if not takingPhotos:\n",
    "        text = 'Node ' + str(node) + ': ['\n",
    "\n",
    "        if len(nodePos) >= node:\n",
    "            if nodePos[node - 1][0] != -1:\n",
    "                text += str(nodePos[node - 1][0]) + ', '\n",
    "            else:\n",
    "                text += ' - , '\n",
    "            if nodePos[node - 1][1] != -1:\n",
    "                text += str(nodePos[node - 1][1]) + '] '\n",
    "            else:\n",
    "                text += '  - ] '\n",
    "        else:\n",
    "            text += ' - ,  - ] '\n",
    "\n",
    "        if cycles != 0:\n",
    "            if left:\n",
    "                text += ' Move: -' + str(cycles)\n",
    "            else:\n",
    "                text += ' Move: +' + str(cycles)\n",
    "\n",
    "        if vl:\n",
    "            cv2.line(frame, pt1 = (frame.shape[1] // 2, 0), pt2 = (frame.shape[1] // 2, frame.shape[0]), color = (0, 0, 255), thickness = 1)\n",
    "\n",
    "        cv2.imshow(\"Frame\", cv2.putText(frame, text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA))\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    \n",
    "# Esta función nos muestra, con algunas anotaciones (Ciclos que giraremos y resultados de los reconocedores) \n",
    "# lo que se está viendo a través de la cámara\n",
    "def showImageClassified(cycles, left, frame, lab, trueLab, nodeLabels): \n",
    "    global rec\n",
    "    recNames = ['1-NN-d+HistBW', '1-NN-d+HistRBG', '1-NN-d+Mat']\n",
    "    if cycles != 0:\n",
    "        if left:\n",
    "            cv2.putText(frame, ' Move: -' + str(cycles), (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, ' Move: +' + str(cycles), (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    cv2.putText(frame, 'True Node: ' + str(trueLab), (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Anotamos los resultados en la imagen (verde si coincide, rojo si son distintos)\n",
    "    if lab != None:\n",
    "        if lab == trueLab:\n",
    "            cv2.putText(frame, recNames[rec] + ': ' + nodeLabels[lab - 1], (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:    \n",
    "            cv2.putText(frame, recNames[rec] + ': ' + nodeLabels[lab - 1], (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        if trueLab == 0:\n",
    "            cv2.putText(frame, recNames[rec] + ': Unknown', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, recNames[rec] + ': Unknown', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow(\"Frame\", frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 1: Obtención del dataset de entrenamiento**\n",
    "\n",
    "El siguiente código nos ayudará a recoger alrededor de 60 imágenes por nodo.\n",
    "- 't' (turn): Gira la cámara según el número de pasos definidos por el usuario.\n",
    "- 'h' (home): Vuelve a la posición inicial.\n",
    "- 'p' (photos): Gira según el ángulo definido hacia la derecha tomando alrededor de 60 fotos y vuelve a la posición original.\n",
    "\n",
    "La manera de conseguir nuestro dataset será primero orientar la cámara mediante comandos 't' de manera que vea la imagen de más a la izquierda de un nodo y guardar esta posición asociándola a un nodo (l), movernos hacia la derecha mediante comandos 't' hasta encontrar la posición de la imagen de más a la derecha del nodo y una vez hecho esto para todos los nodos usaremos el comando 'p' que volverá a la posición inicial y hará un giro de 360 tomando 60 fotos dentro del rango de posiciones de cada nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1: [15, 48]\n",
      "Node 2: [51, 93]\n",
      "Node 3: [96, 156]\n",
      "Node 4: [159, 199]\n",
      "Node 5: [202, 287]\n",
      "Node 6: [317, 367]\n",
      "Node 7: [382, 407]\n",
      "Node 8: [410, 490]\n"
     ]
    }
   ],
   "source": [
    "# Inicializamos variables\n",
    "cycles = 0\n",
    "left = False\n",
    "vl = False\n",
    "node = 1\n",
    "path = 'Dataset/'\n",
    "curPos = 0\n",
    "nodePos = [[15, 48], [51, 93], [96, 156], [159, 199], [202, 287], [317, 367], [382, 407], [410, 490]]\n",
    "takingPhotos = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Definimos la resolución de la cámara\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    # Leer y mostrar (anotado) un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    showImage(cycles, left, frame, node, nodePos, vl)\n",
    "    \n",
    "    # Comprobar el input del usuario\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # q: salir\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "    # h: vuelve a la posición 0\n",
    "    elif key == ord(\"h\"):\n",
    "        Thread(target = moveLeft, args =(curPos, )).start()\n",
    "        \n",
    "    # t: girar en una dirección u otra los ciclos que haya definido el usuario\n",
    "    elif key == ord(\"t\"):\n",
    "        if left:\n",
    "            if curPos - cycles < 0:\n",
    "                cycles = curPos\n",
    "            Thread(target = moveLeft, args =(cycles, )).start() \n",
    "        else:\n",
    "            if curPos + cycles > 512:\n",
    "                cycles = 512 - curPos\n",
    "            Thread(target = moveRight, args =(cycles, )).start()\n",
    "            \n",
    "    # p: tomar 60 fotos mientras se barre el ángulo que haya definido el usuario\n",
    "    elif key == ord('p'):\n",
    "        if min([p for pos in nodePos for p in pos]) >= 0: # Comprobamos que se hayan definido todas las posiciones\n",
    "            Thread(target = get60Images, args =(nodePos, path, )).start()\n",
    "        \n",
    "    # 0-9: nos permite ir escribiendo el número de ciclos\n",
    "    elif key >= 48 and key <= 57:\n",
    "        cycles = cycles * 10 + key - 48\n",
    "        if cycles > 512:\n",
    "            cycles = 512\n",
    "            \n",
    "    # -: cambia el signo del movimiento (- izquierda, + derecha)\n",
    "    elif key == ord(\"-\"):\n",
    "        left = not left\n",
    "        \n",
    "    # DEL: borrar el último dígito de los ciclos que haya definido el usuario\n",
    "    elif key == 8:\n",
    "        cycles = int(cycles // 10)\n",
    "        if cycles <= 0:\n",
    "            cycles = 0\n",
    "            left = False\n",
    "            \n",
    "    # m: incrementar el contador de nodo\n",
    "    elif key == ord(\"m\"):\n",
    "        node += 1\n",
    "        \n",
    "    # n: decrementar el contador de nodo\n",
    "    elif key == ord('n'):\n",
    "        if node > 1:\n",
    "            node -=1\n",
    "            \n",
    "    # l: guarda la posición de la imagen de más a la izquierda de un nodo\n",
    "    elif key == ord(\"l\"):\n",
    "        if len(nodePos) < node:\n",
    "            nodes = len(nodePos)\n",
    "            for i in range(node - nodes):\n",
    "                nodePos.append([-1, -1])\n",
    "        nodePos[node - 1][0] = curPos\n",
    "    \n",
    "    # r: guarda la posición de la imagen de más a la derecha de un nodo\n",
    "    elif key == ord(\"r\"):\n",
    "        if len(nodePos) < node:\n",
    "            nodes = len(nodePos)\n",
    "            for i in range(node - nodes):\n",
    "                nodePos.append([-1, -1])\n",
    "        nodePos[node - 1][1] = curPos\n",
    "        \n",
    "    # z: dibuja una línea vertical en el centro de la imagen (Nos sirve para fijar un punto de partida en la imagen)\n",
    "    elif key == ord(\"z\"):\n",
    "        vl = not vl\n",
    "\n",
    "moveLeft(curPos) # Volvemos a la posición inicial\n",
    "\n",
    "for i in range(len(nodePos)):\n",
    "    print('Node ' + str(i + 1) + ': [' + str(nodePos[i][0]) + ', ' + str(nodePos[i][1]) + ']')\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 2: Reconocedores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** El reconocedor de base de este trabajo práctico es el 1-Nearest Neighbor con umbral ajustable + histograma de grises normalizado,  debido a su simplicidad conceptual y eficiencia  estática y dinámica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedHistogramBW(img):\n",
    "    return cv2.calcHist([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)], [0], None, [256], [0, 256]).ravel() / (img.shape[0] * img.shape[1])\n",
    "    \n",
    "def r1NNdHistBW(img, trainFeatures, trainLabels, threshold):\n",
    "    d = np.linalg.norm(trainFeatures - getNormalizedHistogramBW(img), axis = 1)\n",
    "    idxDmin = d.argmin()\n",
    "    if d[idxDmin] <= threshold:\n",
    "        return trainLabels[idxDmin]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Adicionalmente, se propone trabajar con el 1-NN de umbral ajustable + histograma RGB normalizado y vectorizado(se encadenan en un supervector 256+256+256 elementos) los histogramas RGB normalizados de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedHistogramRBG(img):\n",
    "    return np.vstack(tuple(cv2.calcHist([img], [i], None, [256], [0,256]) for i in range(3))).ravel() / (img.shape[0] * img.shape[1] * 3)\n",
    "\n",
    "def r1NNdHistRBG(img, trainFeatures, trainLabels, threshold):\n",
    "    d = np.linalg.norm(trainFeatures - getNormalizedHistogramRBG(img), axis = 1)\n",
    "    idxDmin = d.argmin()\n",
    "    if d[idxDmin] <= threshold:\n",
    "        return trainLabels[idxDmin]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Adicionalmente, se propone también trabajar con el algoritmo 1-NN de umbral ajustable basado en el concepto de distancia o diferencia de las imágenes matriciales. En este caso se puede experimentar con diversos procedimientos heurísticos de suavizado de las imágenes matriciales(por rango Imax - Imin o aplicando la función de  normalización minmax de opencv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r1NNdMat(img, trainFeatures, trainLabels, threshold):\n",
    "    d = np.square(trainFeatures - cv2.normalize(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)).sum(axis = (1,2)) ** .5\n",
    "    idxDmin = d.argmin()\n",
    "    if d[idxDmin] <= threshold * 500:\n",
    "        return trainLabels[idxDmin]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 3: Pruebas y Testeo del reconocedor de landmarks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.- Creación del Conjunto de Muestras Etiquetadas  CME o data sets de entrenamiento:** \n",
    "se  deben captar al menos 60  tomas para cada uno de los landmarks del mapa-grafo a reconocer, por lo que el data set de entrenamiento y test deberá contar con P datos, con P = (nº landmarks del mapa) x 60:\n",
    "\n",
    "DS = {(x1, α1) ……….. (xP ,αP) }; siendo x el vector de variables discriminantes (histograma de grises normalizado) y α es la etiqueta(landmark) del correspondiente dato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNodes = 8\n",
    "nImgPerNode = 60\n",
    "\n",
    "trainFeatures1NNdHistBW = np.array([getNormalizedHistogramBW(cv2.imread('Dataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg')) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "trainFeatures1NNdHistRBG = np.array([getNormalizedHistogramRBG(cv2.imread('Dataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg')) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "trainFeatures1NNdMat = np.array([cv2.normalize(cv2.imread('Dataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg', cv2.IMREAD_GRAYSCALE), None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "trainFeatures1NNdHistBWNight = np.array([getNormalizedHistogramBW(cv2.imread('NightDataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg')) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "trainFeatures1NNdHistRBGNight = np.array([getNormalizedHistogramRBG(cv2.imread('NightDataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg')) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "trainFeatures1NNdMatNight = np.array([cv2.normalize(cv2.imread('NightDataset/nodo_' + str(n) + '_img_' + str(img) + '.jpg', cv2.IMREAD_GRAYSCALE), None, alpha = 0, beta = 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F) for n in range(1, nNodes + 1) for img in range(nImgPerNode)])\n",
    "\n",
    "trainLabels = np.array([range(0, nNodes)]).repeat(nImgPerNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.-Testeo estático de los reconocedores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LooCrossValidation(fun, features, labels, threshold, settype):\n",
    "    global nImgPerNode\n",
    "    \n",
    "    P = features.shape[0]\n",
    "    nErrors = 0\n",
    "    ind = np.arange(P) # Row indices\n",
    "    \n",
    "    for step in range(P):\n",
    "        label = fun(cv2.imread(settype + 'nodo_' + str((step // nImgPerNode) + 1) + '_img_' + str(step % nImgPerNode) + '.jpg'), features[ind != step, :], labels[ind != step], threshold)\n",
    "        if label != labels[step]:\n",
    "            nErrors += 1\n",
    "    \n",
    "    print('True error rate % = ' + str((nErrors / P) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **a)Testeo estático del reconocedor básico:** se estimarán las tasas de errores por el método de validación cruzada “leave-one-out” del reconocedor básico (1-NN con umbral ajustable + histograma normalizado de grises)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdHistBW, trainFeatures1NNdHistBW, trainLabels, 0.1, 'Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdHistBW, trainFeatures1NNdHistBWNight, trainLabels, 0.1, 'NightDataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **b)Testeo estático del reconocedor 1-NN de umbral ajustable + histograma RGB normalizado y vectorizado:** se estimarán las tasas de errores por el método de validación cruzada “leave-one-out” del reconocedor 1-NN de umbral ajustable + histograma RGB normalizado y vectorizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdHistRBG, trainFeatures1NNdHistRBG, trainLabels, 0.1, 'Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 0.20833333333333334\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdHistRBG, trainFeatures1NNdHistRBGNight, trainLabels, 0.1, 'NightDataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **c)Testeo estático del reconocedor 1-NN de umbral ajustable basado en el concepto de distancia o diferencia de las imágenes matriciales:** se estimarán las tasas de errores por el método de validación cruzada “leave-one-out” del reconocedor 1-NN de umbral ajustable basado en el concepto de distancia o diferencia de las imágenes matriciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 2.5\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdMat, trainFeatures1NNdMat, trainLabels, 0.1, 'Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True error rate % = 6.041666666666667\n"
     ]
    }
   ],
   "source": [
    "LooCrossValidation(r1NNdMat, trainFeatures1NNdMatNight, trainLabels, 0.1, 'NightDataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.- Testeo dinámico del  navegador:** una vez  testeado en estática el reconocedor del navegador, pasamos al testeo dinámico contra vídeos de recorridos del entorno de navegación para estimar la eficiencia del navegador en el reconocimiento de los landmarks del  entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recNames = ['1-NN-d+HistBW', '1-NN-d+HistRBG', '1-NN-d+Mat']\n",
    "\n",
    "videoPos = [[170, 240], [245, 410], [415, 645], [650, 850], [855, 1300], [1410, 1610], [1670, 1790], [1795, 2150]]\n",
    "nightVideoPos = [[110, 185], [190, 305], [310, 440], [445, 545], [550, 795], [850, 970], [1000, 1070], [1075, 1300]]\n",
    "out = True\n",
    "curFrame = 0\n",
    "\n",
    "nErrors = 0\n",
    "\n",
    "nodeLabels = ['Guitarras', 'Television', 'Cortina', 'Sofa', 'Mesa', 'Teclados', 'Bano', 'Escaleras']\n",
    "\n",
    "trueLab = 0\n",
    "rec = 1\n",
    "\n",
    "cap = cv2.VideoCapture('./NightVideo.avi')\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "videoWriter = cv2.VideoWriter('/Users/fer/Documents/UPM/Master_IA/RA/Reconocedor/video2_rec2.avi', fourcc, 30.0, (640,480))\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "while(ret):\n",
    "    \n",
    "    if out:\n",
    "        if videoPos[trueLab][0] == curFrame:\n",
    "            out = False\n",
    "    else:\n",
    "        if videoPos[trueLab][1] == curFrame:\n",
    "            trueLab += 1\n",
    "            out = True\n",
    "            if trueLab >= len(videoPos):\n",
    "                trueLab = 0\n",
    "    \n",
    "    # Hacemos la clasificación con los 3 reconocedores\n",
    "    if rec == 0:\n",
    "        lab = r1NNdHistBW(frame, trainFeatures1NNdHistBW, trainLabels, 0.1)\n",
    "    elif rec == 1:\n",
    "        lab = r1NNdHistRBG(frame, trainFeatures1NNdHistRBGNight, trainLabels, 0.1)\n",
    "    elif rec == 2:\n",
    "        lab = r1NNdMat(frame, trainFeatures1NNdMat, trainLabels, 0.1)\n",
    "\n",
    "    if out:\n",
    "        cv2.putText(frame, 'Unknown', (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(frame, nodeLabels[trueLab], (50, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "    # Anotamos los resultados en la imagen (verde si coincide, rojo si son distintos)\n",
    "    if lab != None:\n",
    "        if not out and lab == trueLab:\n",
    "            cv2.putText(frame, recNames[rec] + ': ' + nodeLabels[lab], (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:    \n",
    "            cv2.putText(frame, recNames[rec] + ': ' + nodeLabels[lab], (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            nErrors += 1\n",
    "    else:\n",
    "        if out:\n",
    "            cv2.putText(frame, recNames[rec] + ': Unknown', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, recNames[rec] + ': Unknown', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "            nErrors += 1\n",
    "            \n",
    "    videoWriter.write(frame)\n",
    "    \n",
    "    # Comprobar el input del usuario\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # q: salir\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "            \n",
    "    # m: siguiente reconocedor\n",
    "    elif key == ord(\"m\"):\n",
    "        if rec < 2:\n",
    "            rec += 1\n",
    "        \n",
    "    # n: reconocedor anterior\n",
    "    elif key == ord(\"n\"):\n",
    "        if rec > 0:\n",
    "            rec -= 1\n",
    "            \n",
    "    ret, frame = cap.read()\n",
    "    curFrame += 1\n",
    "    \n",
    "print('True error rate % = ' + str((nErrors / (curFrame - 1)) * 100))\n",
    "            \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "videoWriter.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos el código para hacer testeo dinámico en el robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeLabels = ['Guitarras', 'Television', 'Cortina', 'Sofa', 'Mesa', 'Teclados', 'Bano', 'Escaleras']\n",
    "nodePos = [[15, 48], [51, 93], [96, 156], [159, 199], [202, 287], [317, 367], [382, 407], [410, 490]]\n",
    "\n",
    "# Inicializamos variables\n",
    "cycles = 0\n",
    "left = False\n",
    "curPos = 0\n",
    "trueLab = 0\n",
    "rec = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Definimos la resolución de la cámara\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while(True):\n",
    "    # Leer y mostrar (anotado) un frame de la cámara\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Hacemos la clasificación con los 3 reconocedores\n",
    "    if rec == 0:\n",
    "        lab = r1NNdHistBW(frame, trainFeatures1NNdHistBW, trainLabels, 0.1)\n",
    "    elif rec == 1:\n",
    "        lab = r1NNdHistRBG(frame, trainFeatures1NNdHistRBG, trainLabels, 0.1)\n",
    "    elif rec == 2:\n",
    "        lab = r1NNdMat(frame, trainFeatures1NNdMat, trainLabels, 0.1)\n",
    "    trueLab = 0\n",
    "    for i in range(len(nodePos)):\n",
    "        if nodePos[i][0] <= curPos and nodePos[i][1] >= curPos:\n",
    "            trueLab = i + 1\n",
    "    \n",
    "    showImageClassified(cycles, left, frame, lab, trueLab, nodeLabels)\n",
    "    \n",
    "    # Comprobar el input del usuario\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # q: salir\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "            \n",
    "    # h: vuelve a la posición 0\n",
    "    elif key == ord(\"h\"):\n",
    "        Thread(target = moveLeft, args =(curPos, )).start()\n",
    "        \n",
    "    # t: girar en una dirección u otra los ciclos que haya definido el usuario\n",
    "    elif key == ord(\"t\"):\n",
    "        if left:\n",
    "            if curPos - cycles < 0:\n",
    "                cycles = curPos\n",
    "            Thread(target = moveLeft, args =(cycles, )).start() \n",
    "        else:\n",
    "            if curPos + cycles > 512:\n",
    "                cycles = 512 - curPos\n",
    "            Thread(target = moveRight, args =(cycles, )).start()\n",
    "        \n",
    "    # 0-9: nos permite ir escribiendo el número de ciclos\n",
    "    elif key >= 48 and key <= 57:\n",
    "        cycles = cycles * 10 + key - 48\n",
    "        if cycles > 512:\n",
    "            cycles = 512\n",
    "            \n",
    "    # -: cambia el signo del movimiento (- izquierda, + derecha)\n",
    "    elif key == ord(\"-\"):\n",
    "        left = not left\n",
    "        \n",
    "    # DEL: borrar el último dígito de los ciclos que haya definido el usuario\n",
    "    elif key == 8:\n",
    "        cycles = int(cycles // 10)\n",
    "        if cycles <= 0:\n",
    "            cycles = 0\n",
    "            left = False\n",
    "            \n",
    "    # m: siguiente reconocedor\n",
    "    elif key == ord(\"m\"):\n",
    "        if rec < 2:\n",
    "            rec += 1\n",
    "        \n",
    "    # n: reconocedor anterior\n",
    "    elif key == ord(\"n\"):\n",
    "        if rec > 0:\n",
    "            rec -= 1\n",
    "            \n",
    "moveLeft(curPos) # Volvemos a la posición inicial\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos también un código para grabar un video de un giro de 360 grados en el robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "working = True\n",
    "started = False\n",
    "\n",
    "def tour():\n",
    "    global working\n",
    "    time.sleep(3)\n",
    "    start()\n",
    "    for i in range(512):\n",
    "        for halfstep in range(8): \n",
    "            for pin in range(4):  \n",
    "                GPIO.output(hMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.02)\n",
    "    for i in range(512):\n",
    "        for halfstep in reversed(range(8)):\n",
    "            for pin in reversed(range(4)):\n",
    "                GPIO.output(hMotorPins[pin], motorSequence[halfstep][pin])\n",
    "            time.sleep(0.001)\n",
    "    stop()\n",
    "    working = False\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Definimos la resolución de la cámara\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "videoWriter = cv2.VideoWriter('/home/pi/Desktop/video.avi', fourcc, 30.0, (640,480))\n",
    "\n",
    "while (working):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        #cv2.imshow('video', frame)\n",
    "        videoWriter.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "    # Comprobar el input del usuario\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    # q: salir\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "    if not started:\n",
    "        Thread(target = tour, args =( )).start() \n",
    "        started = True\n",
    "\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
